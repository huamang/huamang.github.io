{"meta":{"title":"Huamang's Blog","subtitle":"向美好的日子进发","description":"回避现实的人，未来将更不理想","author":"huamang","url":"http://example.com","root":"/"},"pages":[{"title":"about","date":"2020-12-24T06:42:35.000Z","updated":"2020-12-24T07:35:50.066Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"向美好的日子出发 我的CSDN：https://blog.csdn.net/m0_51078229"},{"title":"tags","date":"2020-12-24T06:45:13.000Z","updated":"2020-12-24T07:22:42.156Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"PHP学习笔记","slug":"PHP学习笔记","date":"2021-01-15T16:00:00.000Z","updated":"2021-01-15T18:26:21.412Z","comments":true,"path":"2021/01/16/PHP学习笔记/","link":"","permalink":"http://example.com/2021/01/16/PHP%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"php学习开始，在这记录我觉得需要注意的地方 变量变量定义： “$”前面加上这个就是变量 变量名不能以数字开头 将变量从内存中删除使用unset($变量名)函数来删除变量 预定义变量预定义变量：提前定义的变量，系统定义的变量，存储许多需要用到的数据（预定义变量都是数组）$_GET：获取所有表单以get方式提交的数据$_POST：POST提交的数据都会保存在此$_REQUEST：GET和POST提交的都会保存$GLOBALS：PHP中所有的全局变量$_SERVER：服务器信息$_SESSION：session会话数据$_COOKIE：cookie会话数据$_ENV：环境信息$_FILES：用户上传的文件信息 可变变量可变变量：如果一个变量保存的值刚好是另外一个变量的名字，那么可以直接通过访问一个变量得到另外一个变量的值：在变量前面再多加一个$符号。 123$a=&#x27;b&#x27;$b=&#x27;c&#x27;echo $$a $$a就相当于$b就是c 变量传值分为两种，一个是值传递，一个是引用传递 值传递值传递：将变量保存的值赋值一份，然后将新的值给另外一个变量保存（两个变量没有关系）a就对应a的值，b就对应b的值 引用传递引用传递：将变量保存的值所在的内存地址，传递给另外一个变量：两个变量指向同一块内存空间（两个变量是同一个值）$新变量=&amp;$老变量这个方式给变量赋值是让两个变量名指向同一个值，就像一棵树上的两个枝干，都是连着一个树根所以改变了任何一个的值，两个的值都会改变 常量常量的定义有两种定义方式，define函数和const关键字 define函数：define(&#39;常数名&#39;,值) const关键字const 常量名 = 值 命名规则 常量命名不需要”$”，使用了这个符号就会被认为是变量 常量一波用大写，但是默认不区分大小写 魔术常量他们有双下划线开始+长两名+双下划线结束，这种常量称之为系统魔术常量：魔术常量的值通常会跟着环境变化，但是用户改变不了 __DIR__：当前被执行的脚本所在电脑的绝对路径 __FILE__：当前被执行的脚本所在的电脑的绝对路径（带自己文件的名字） __LINE__：当前所属的行数 __NAMESPACE__：当前所属的命名空间 __CLASS__：当前所属的类 __METHOD__：当前所属的方法 数据类型PHP是一种弱类型语言，变量本身没有数据类型。 php的八种数据类型 整型：int/integer，系统分配4个字节存储，表示整数类型（有前提） 浮点型：float/double，系统分配8个字节存储，表示小数或者整型存不下的整数 字符串型：string，系统根据实际长度分配，表示字符串（引号） 布尔类型：bool/boolean，表示布尔类型，只有两个值：true和false 复合数据类型：2个小类 对象类型：object，存放对象（面向对象） 数组类型：array，存储多个数据（一次性） 特殊数据类型：2个小类 资源类型：resource，存放资源数据（PHP外部数据，如数据库、文件） 空类型：NULL，只有一个值就是NULL（不能运算） 强制转换 强制转换规则：在变量之前增加一个括号()，然后在里面写上对应类型：int/integer….其中NULL类型用到unset() 其他类型转数值的说明1、 布尔true为1，false为0；2、 字符串转数值有自己的规则 2.1 以字母开头的字符串，永远为0；2.2 以数字开头的字符串，取到碰到字符串为止（不会同时包含两个小数点） 类型判断 is_开头后面跟类型名字的函数：is_XXX(变量名) 布尔类型不能用echo来访问，无法区分是布尔的true还是字符串的true，所以有个函数var_dump(变量1，变量2...)这个函数会返回变量的类型和值 Gettype(变量名)：获取类型，得到的是该类型对应的字符串 Settype(变量名,类型)：设定数据类型：与强制转换不同：1、 强制转换(类型)变量名，是对数据值复制的内容进行处理（不会处理实际存储的内容）2、 settype会直接改变数据本身整数类型4个字节存储数据，最大就是32位","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"},{"name":"PHP","slug":"PHP","permalink":"http://example.com/tags/PHP/"}]},{"title":"爬虫笔记4模拟登陆","slug":"爬虫笔记4模拟登陆","date":"2021-01-12T16:00:00.000Z","updated":"2021-01-13T12:41:11.246Z","comments":true,"path":"2021/01/13/爬虫笔记4模拟登陆/","link":"","permalink":"http://example.com/2021/01/13/%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B04%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86/","excerpt":"","text":"这次模拟4399的登陆这篇不难，主要是学到了这几点 requests模块有个session方法可以记录网页的cookie 模拟登陆的时候有两个请求，第一个是用来登陆的，第二个是用来保存登陆界面的 一般的登陆都是post传参但是我们只需要提供用户名和密码就可以这样写123data=&#123;&#125;data[&quot;username&quot;]=&quot;1093533435&quot;data[&quot;password&quot;]=&quot;liouyuwen&quot; 先附上源代码123456789101112import requestssession=requests.Session()url=&quot;https://ptlogin.4399.com/ptlogin/login.do?v=1&quot;urlpro=&quot;https://u.4399.com/profile/&quot;headers=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot;&#125;data=&#123;&#125;data[&quot;username&quot;]=&quot;xxxxxx&quot;data[&quot;password&quot;]=xxxxxx&quot;res=session.post(url=url,data=data,headers=headers)profile=session.get(url=urlpro,headers=headers).textwith open(&quot;4399.html&quot;,&quot;w&quot;,encoding=&#x27;utf-8&#x27;) as fp: fp.write(profile) 调用Session方法12import requestssession=requests.Session() 此后所有的请求就不用requests.get/post而使用session.get或session.post 配置爬虫发起请求12345678url=&quot;https://ptlogin.4399.com/ptlogin/login.do?v=1&quot;urlpro=&quot;https://u.4399.com/profile/&quot;headers=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot;&#125;data=&#123;&#125;data[&quot;username&quot;]=&quot;xxxxxx&quot;data[&quot;password&quot;]=xxxxxx&quot;res=session.post(url=url,data=data,headers=headers)profile=session.get(url=urlpro,headers=headers).text 第一个请求不需要在后面加格式，就是用来发起请求，得到cookie并登入进去第二个请求就是用来获取登入后的界面的 文件保存12with open(&quot;4399.html&quot;,&quot;w&quot;,encoding=&#x27;utf-8&#x27;) as fp: fp.write(profile) 可以看到已经爬出来了","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"cookie","slug":"cookie","permalink":"http://example.com/tags/cookie/"}]},{"title":"aiohttp的学习使用","slug":"asyncio库的细化学习","date":"2021-01-11T16:00:00.000Z","updated":"2021-01-13T02:18:59.080Z","comments":true,"path":"2021/01/12/asyncio库的细化学习/","link":"","permalink":"http://example.com/2021/01/12/asyncio%E5%BA%93%E7%9A%84%E7%BB%86%E5%8C%96%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"前面博客讲的太泛了，对于我搞爬虫就细化学习理解一波，基于这篇博客的学习由于requests库和asyncio库是不能一起使用的，所以我们要安装一点小插件pip install aiohttp先上代码 12345678910111213141516171819202122232425import asyncioimport aiohttpasync def func(url): headers = &#123; &quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot; &#125; print(&#x27;开始下载&#x27;,url) async with aiohttp.ClientSession() as session: async with await session.get(url=url,headers=headers) as response: data = await response.read() name = url.split(&#x27;/&#x27;)[-1] with open(name,&#x27;wb&#x27;) as fp: fp.write(data) print(&#x27;下载完成&#x27;,url)urls = [&#x27;https://ziyuan.jumpw.com/heroactivity/cases2020/anniversary/images/img_01.png&#x27;, &#x27;https://ziyuan.jumpw.com/heroactivity/cases2020/anniversary/images/img_02.png&#x27;, &#x27;https://ziyuan.jumpw.com/heroactivity/cases2020/anniversary/images/img_03.png&#x27; ]tasks=[]for url in urls: a = func(url) task = asyncio.ensure_future(a) tasks.append(task)loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) 基本步骤： 导入库 这里注意不使用requests了，直接使用aiohttp 12import asyncioimport aiohttp 建立任务单 1234urls = [&#x27;https://ziyuan.jumpw.com/heroactivity/cases2020/anniversary/images/img_01.png&#x27;, &#x27;https://ziyuan.jumpw.com/heroactivity/cases2020/anniversary/images/img_02.png&#x27;, &#x27;https://ziyuan.jumpw.com/heroactivity/cases2020/anniversary/images/img_03.png&#x27; ] 用循环对每一条任务进行操作1for url in urls: 创建协程对象1a = func(url) 将任务封装 使用asyncio.ensure_future()来封装ensure_future 其实是用来创建任务的 123tasks = [] # 这个写在循环外面task = asyncio.ensure_future(a)tasks.append(task) 建立事件循环 利用asyncio.get_event_loop()创建事件循环 1loop = asyncio.get_event_loop() 把任务列表放到事件循环里面运行 运用这个函数执行运行任务单.run_until_complete()这个函数的参数是future或者协程这个函数asyncio.wait()叫简单等待如果参数可以是一个任务单列表，如果里面有协程（或者其他的可等待对象）它将自动作为任务加入日程。 1loop.run_until_complete(asyncio.wait(tasks)) 定义一个爬虫协程 这个爬虫的特点是url要从外面导入注意的是aiohttp的使用格式比较固定，套着用就是了 12345678910111213141516171819async def func(url): headers = &#123; &quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot; &#125; print(&#x27;开始下载&#x27;,url) # 类似于上下文管理器，就是with open,with前面一定要加async，固定写法 # as session是类似起名字一样 async with aiohttp.ClientSession() as session: # async with跟上面同理，await是手动挂起，因为向图片发起请求是IO操作 async with await session.get(url=url,headers=headers) as response: # 同样的，对返回的数据进行解析也是IO操作 # 不同于requests模块，read()指的是解析二进制数据 # text() 就是我们平时用的text # 而json对象则要用json() data = await response.read() name = url.split(&#x27;/&#x27;)[-1] with open(name,&#x27;wb&#x27;) as fp: fp.write(data) print(&#x27;下载完成&#x27;,url) 运行一波啪的一下很快啊","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"协程","slug":"协程","permalink":"http://example.com/tags/%E5%8D%8F%E7%A8%8B/"},{"name":"事件循环","slug":"事件循环","permalink":"http://example.com/tags/%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF/"},{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"协程asyncio库的学习和理解","slug":"协程asyncio库的学习与理解","date":"2021-01-09T16:00:00.000Z","updated":"2021-01-13T02:18:58.183Z","comments":true,"path":"2021/01/10/协程asyncio库的学习与理解/","link":"","permalink":"http://example.com/2021/01/10/%E5%8D%8F%E7%A8%8Basyncio%E5%BA%93%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%90%86%E8%A7%A3/","excerpt":"","text":"基于python文档和一些大佬的博客学习，谈谈我对于协程的学习与理解协程：coroutine ，简写成：coro 协程函数: 定义形式为 async def 的函数; 协程对象: 调用 协程函数 所返回的对象。协程通过 async/await 语法进行声明 定义函数的时候再头上加一个async就变成了协程 调用的时候也要在函数名前加上await123456import asyncioasync def do(): print(&#x27;hello&#x27;) await asyncio.sleep(1) print(&#x27;world&#x27;)asyncio.run(do()) 简单地调用一个协程并不会将其加入执行日程 运行 asyncio 程序asyncio.run(coro, *, debug=False) 执行 coroutine（协程） coro 并返回结果。 如果 debug 为 True，事件循环将以调试模式运行。 此函数总是会创建一个新的事件循环并在结束时关闭之。它应当被用作 asyncio 程序的主入口点，理想情况下应当只被调用一次。 用来运行最高层级的入口点”do()”函数上面的实例就使用了这个函数 123456import asyncioasync def do(): print(&#x27;hello&#x27;) await asyncio.sleep(1) print(&#x27;world&#x27;)asyncio.run(do()) 等待12345678910111213141516import asyncioimport timeasync def say_after(delay, what): await asyncio.sleep(delay) print(what)async def main(): print(&quot;started at&quot;, time.strftime(&#x27;%X&#x27;)) await say_after(1, &#x27;hello&#x27;) await say_after(2, &#x27;world&#x27;) print(&quot;started at&quot;, time.strftime(&#x27;%X&#x27;))asyncio.run(main()) 简单等待asyncio.wait(aws, *, loop=None, timeout=None, return_when=ALL_COMPLETED) 并发运行 aws 指定的 可等待对象 并阻塞线程直到满足 return_when 指定的条件。 如果 aws 中的某个可等待对象为协程，它将自动作为任务加入日程。 返回两个 Task/Future 集合: (done, pending)。 于是就可以这样调用，实现并发运行 1loop.run_until_complete(asyncio.wait(任务单（可为一个列表）)) 可等待对象如果一个对象可以在 await 语句中使用，那么它就是 可等待 对象有三种主要类型: 协程, 任务 和 Future. 协程协程属于可等待对象，因此可以在其他协程中被等待:（可用await被调用） 协程函数: 定义形式为 async def 的函数; 协程对象: 调用 协程函数 所返回的对象。 12345678910import asyncioasync def nested(): return 42async def main(): nested() # 用await调用协程 print(await nested())asyncio.run(main()) 直接调用nested就报错，说没有用await第二个用来await声明就可以调用了 任务任务 被用来设置日程以便 并发 执行协程。当一个协程通过 asyncio.create_task() 等函数被打包为一个 任务，该协程将自动排入日程准备立即运行 123456789import asyncioasync def nested(): return 42async def main():# 将nested函数用下面的方法打包成一个任务task# 用await调用任务 task = asyncio.create_task(nested()) await taskasyncio.run(main()) FuturesFuture 是一种特殊的 低层级 可等待对象，表示一个异步操作的 最终结果。当一个 Future 对象 被等待，这意味着协程将保持等待直到该 Future 对象在其他地方操作完毕。通常情况下 没有必要 在应用层级的代码中创建 Future 对象。 创建任务asyncio.create_task(coro) 该函数用来并发运行作为 asyncio 任务 的多个协程。 将 coro 协程 打包为一个 Task 排入日程准备执行。返回 Task 对象。事件循环asyncio.get_running_loop()返回当前 OS 线程中正在运行的事件循环。如果没有正在运行的事件循环则会引发 RuntimeError。 此函数只能由协程或回调来调用。该任务会在 get_running_loop() 返回的循环中执行，如果当前线程没有在运行的循环则会引发 RuntimeError。 1234567891011121314151617181920import asyncioimport time# 创建一个延迟函数，控制延迟运行async def say_after(delay, what): await asyncio.sleep(delay) print(what) async def main(): task1 = asyncio.create_task( say_after(1, &#x27;hello&#x27;)) task2 = asyncio.create_task( say_after(2, &#x27;world&#x27;)) print(&quot;started at&quot;, time.strftime(&#x27;%X&#x27;)) # 两个task就像一个代办的任务，然后带着await执行他们 await task1 await task2 print(&quot;started at&quot;, time.strftime(&#x27;%X&#x27;))asyncio.run(main()) 可以发现运行时间和上面写的代码不一样了，就只有我们设置的最长的等待时间：两秒，说明实现了并发运行 休眠asyncio.sleep(delay, result=None) 阻塞：delay 指定的秒数 如果指定了 result，则当协程完成时将其返回给调用者 sleep() 总是会挂起当前任务，以允许其他任务运行 事件循环获取时间循环asyncio.get_running_loop()：返回当前 OS 线程中正在运行的事件循环，如果没有正在运行的事件循环则会引发 RuntimeError。 asyncio.get_event_loop()：获取当前事件循环， 如果当前 OS 线程没有设置当前事件循环并且 set_event_loop() 还没有被调用，asyncio 将创建一个新的事件循环并将其设置为当前循环 asyncio.set_event_loop(loop)：将 loop 设置为当前 OS 线程的当前事件循环 asyncio.new_event_loop()：创建一个新的事件循环 运行和停止loop.run_until_complete(future)：运行直到 future ( Future 的实例 ) 被完成如果参数是 coroutine object（协程） ，将被隐式调度为 asyncio.Task 来运行 loop.run_forever()：运行事件循环直到 stop() 被调用 loop.stop()：停止事件循环 学到这里，就有能力看懂小泽的这段代码了1234567891011121314151617181920212223242526272829import asyncioimport timeasync def english(): print(&#x27;小明正在学英语...&#x27;) await asyncio.sleep(2) print(&#x27;小明已经学了两秒英语...&#x27;)async def math(): print(&#x27;小明正在学数学...&#x27;) await asyncio.sleep(2) print(&#x27;小明已经学了两秒数学...&#x27;)async def zhexue(): print(&#x27;小明正在学哲学...&#x27;) await asyncio.sleep(4) print(&#x27;小明已经学了四秒哲学...&#x27;)if __name__ == &#x27;__main__&#x27;: start = time.time() # 建立任务库 renwu = [english(),math(),zhexue()] # 初始化地盘 dipan = asyncio.get_event_loop() # 放置任务 dipan.run_until_complete(asyncio.wait(renwu)) # 结束计时 end = time.time() print(&#x27;小明学完所有课程啦！总用时：&#x27;+str(end-start)+&#x27;秒！&#x27;)","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"协程","slug":"协程","permalink":"http://example.com/tags/%E5%8D%8F%E7%A8%8B/"},{"name":"事件循环","slug":"事件循环","permalink":"http://example.com/tags/%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF/"},{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"爬虫学习笔记3","slug":"爬虫入门学习笔记3","date":"2021-01-04T17:21:45.769Z","updated":"2021-01-04T17:23:24.029Z","comments":true,"path":"2021/01/05/爬虫入门学习笔记3/","link":"","permalink":"http://example.com/2021/01/05/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03/","excerpt":"","text":"爬虫入门学习笔记3get()和post()的数据请求 在get()里面叫paramas 在post()里面叫data 尝试动态页面的爬取（豆瓣排名）老规矩，先附上源代码： 1234567891011121314151617181920212223242526272829303132333435import requestsimport jsonurl=&#x27;https://movie.douban.com/j/chart/top_list?&#x27;header=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot;&#125;params = &#123; &#x27;type&#x27;:&#x27;5&#x27;, &#x27;interval_id&#x27;:&#x27;100:90&#x27;, &#x27;action&#x27;:&#x27;&#x27;, &#x27;start&#x27;: &#x27;0&#x27;, &#x27;limit&#x27;:&#x27;20&#x27;&#125;response=requests.get(url=url,headers=header,params=params).content.decode()res=json.loads(response)for i in res: rating = i[&#x27;rating&#x27;][0] rank = i[&#x27;rank&#x27;] types = i[&#x27;types&#x27;] typess = &#x27;&#x27; for a in types: typess += a typess += &#x27;/&#x27; regions = i[&#x27;regions&#x27;][0] date = i[&#x27;release_date&#x27;] title = i[&#x27;title&#x27;] actors = i[&#x27;actors&#x27;] actorss = &#x27;&#x27; for b in actors: actorss += b actorss += &#x27;/&#x27; print(&#x27;电影名字：&#x27; + title) print(&#x27;排名：&#x27;,rank) print(&#x27;评分：&#x27; + rating) print(&#x27;主演：&#x27; + actorss) print(&#x27;上映时间：&#x27; + date + &#x27;/上映地区：&#x27; + regions + &#x27;/分类：&#x27; + typess) print(&#x27;-------------------------------------------------------------------&#x27;) 失败的尝试一开始使用xpath来爬取这个文本，但是发现不得行，爬了一个寂寞给我，后来了解到这是一个动态的页面，所以我们回忆起爬取有道翻译怎么操作的 必要信息的提取 打开network勾到XHR，看响应头，发现第三个是有效的信息 目标确定，接下来就是获取必要的信息来配置爬虫 找出真正的url 发现提交方式是get 发现返回的是json格式 翻到最下面，找到get请求的数据paramas配置好爬虫 之前爬取有道翻译的时候也涉及了json解密。 response=requests.get(url=url,headers=header,params=params).content.decode()对于这后面的.content.decode()这里说一下我的理解：由于返回的是json格式，不能用文本方式爬取，所以用最最基本的二进制方式爬取就对了，decode()指的是编码方式，默认就是字符串方式，刚好我们json.loads()就是要处理字符串12345678910111213import requestsimport jsonurl=&#x27;https://movie.douban.com/j/chart/top_list?&#x27;header=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot;&#125;params = &#123; &#x27;type&#x27;:&#x27;5&#x27;, &#x27;interval_id&#x27;:&#x27;100:90&#x27;, &#x27;action&#x27;:&#x27;&#x27;, &#x27;start&#x27;: &#x27;0&#x27;, &#x27;limit&#x27;:&#x27;20&#x27;&#125;response=requests.get(url=url,headers=header,params=params).content.decode()res=json.loads(response) 数据的处理 解码出来的res是一个列表，列表里面是一个个的字典，每个字典代表一个电影 由于不美观，所我处理了一个电影好观察字典的键和值的对应关系这样就一目了然了照着这个处理后的字典，数据处理很简单，就不多说了12345678910111213141516171819202122for i in res: rating = i[&#x27;rating&#x27;][0] rank = i[&#x27;rank&#x27;] types = i[&#x27;types&#x27;] typess = &#x27;&#x27; for a in types: typess += a typess += &#x27;/&#x27; regions = i[&#x27;regions&#x27;][0] date = i[&#x27;release_date&#x27;] title = i[&#x27;title&#x27;] actors = i[&#x27;actors&#x27;] actorss = &#x27;&#x27; for b in actors: actorss += b actorss += &#x27;/&#x27; print(&#x27;电影名字：&#x27; + title) print(&#x27;排名：&#x27;,rank) print(&#x27;评分：&#x27; + rating) print(&#x27;主演：&#x27; + actorss) print(&#x27;上映时间：&#x27; + date + &#x27;/上映地区：&#x27; + regions + &#x27;/分类：&#x27; + typess) print(&#x27;-------------------------------------------------------------------&#x27;)","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"},{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"爬虫学习笔记2","slug":"爬虫入门学习笔记2","date":"2021-01-03T14:48:23.077Z","updated":"2021-01-04T17:23:22.553Z","comments":true,"path":"2021/01/03/爬虫入门学习笔记2/","link":"","permalink":"http://example.com/2021/01/03/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/","excerpt":"","text":"爬虫入门学习笔记2一篇博客写太多不好翻，另起一篇来写 尝试更复杂的图片爬取这次玩个更难的试试，这个网址是泽上荧光大佬提供的，比较简单好欺负，我是一个猫奴，我们就不爬涩图，爬点小猫来玩玩，这个网址是很多辑，每一辑都有若干张图片可以发现每一辑里面是第几张图片网页的后面就会加上几个数字，我们就要利用这个小细节把页面里的所有图片都给他爬下来先附上完整代码：代码是参考小泽大佬的（基本就是硬搬hhh） 1234567891011121314151617181920212223242526import requestsfrom lxml import etreeimport osurl=&quot;http://www.win4000.com/zt/mao.html&quot;header=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot;&#125;response=requests.get(url=url,headers=header).texttree = etree.HTML(response)leaf=tree.xpath(&#x27;//div[@class=&quot;tab_tj&quot;]//ul[@class=&quot;clearfix&quot;]/li/a/@href&#x27;)if not os.path.exists(&#x27;./maomao&#x27;): os.mkdir(&#x27;./maomao&#x27;)for a in leaf: try: b=1 while b&lt;11: c = a.split(&#x27;.html&#x27;)[0] d = c+&#x27;_&#x27;+str(b)+&#x27;.html&#x27; b += 1 e = requests.get(url=d,headers=header).text f = etree.HTML(e) g = f.xpath(&#x27;//div[@class=&quot;main&quot;]//div[@class=&quot;pic-meinv&quot;]/a/img/@src&#x27;)[0] h = requests.get(url=g,headers=header).content i = &#x27;maomao/&#x27;+g.split(&#x27;/&#x27;)[-1] with open(i,&#x27;wb&#x27;) as fp: fp.write(h) except : print(&quot;出错了&quot;) 老套路上他就完了12345678import requestsfrom lxml import etreeimport osurl=&quot;http://www.win4000.com/zt/dongman.html&quot;header=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot;&#125;response=requests.get(url=url,headers=header).texttree = etree.HTML(response)leaf=tree.xpath(&#x27;//div[@class=&quot;tab_tj&quot;]//ul[@class=&quot;clearfix&quot;]/li/a/@href&#x27;) 文件比较多，我们创建一个文件夹创建文件夹叫maomao 12if not os.path.exists(&#x27;./maomao&#x27;): os.mkdir(&#x27;./maomao&#x27;) 图片的爬取之前我们爬取的网页都放在了leaf这个列表里，我们现在要打开那个链接把里面的图片一张张爬下来 因为不知道每一辑有多少图片，所以我们可以使用try语句防止运行的终止 12for a in leaf: try: 在每一辑中，每爬取一张图片就要打开下一个页面，爬取这一辑的下一张图片，所以我们设计一个循环，每次循环都在后边加一 12345678910for a in leaf: try: b=1 while b&lt;11: c = a.split(&#x27;.html&#x27;)[0] d = c+&#x27;_&#x27;+str(b)+&#x27;.html&#x27; b += 1 e = requests.get(url=d,headers=header).text f = etree.HTML(e) g = f.xpath(&#x27;//div[@class=&quot;main&quot;]//div[@class=&quot;pic-meinv&quot;]/a/img/@src&#x27;)[0] 关于这一步这个[0]，f.xpath(xxxx)返回的是一个列表，在这一步中列表就只有一个元素就是那个地址，后面加[0]实际上就是选择了这个地址元素并赋值给了g这个变量，所以g这个变量就可以直接当url了g = f.xpath(&#39;//div[@class=&quot;main&quot;]//div[@class=&quot;pic-meinv&quot;]/a/img/@src&#39;)[0] 爬取图片并储存到maomao文件夹中 上次说了图片要二进制爬取注意一个小细节，给图片命名的时候在前面加上了”maomao/“把路径指向了maomao文件夹 12345678910111213141516for a in leaf: try: b=1 while b&lt;11: c = a.split(&#x27;.html&#x27;)[0] d = c+&#x27;_&#x27;+str(b)+&#x27;.html&#x27; b += 1 e = requests.get(url=d,headers=header).text f = etree.HTML(e) g = f.xpath(&#x27;//div[@class=&quot;main&quot;]//div[@class=&quot;pic-meinv&quot;]/a/img/@src&#x27;)[0] h = requests.get(url=g,headers=header).content i = &#x27;maomao/&#x27;+g.split(&#x27;/&#x27;)[-1] with open(i,&#x27;wb&#x27;) as fp: fp.write(h) except : print(&quot;出错了&quot;) 大功告成！！！ 尝试有道翻译功能的动态爬取有道翻译是加密了的，不能直接爬取，具体解密可以看这个大佬学长的博客看了群里一个师傅发的代码，说吧url里的_o删掉就好了，我一试，还真行。先附上完整代码 1234567891011121314151617181920212223import requestsimport jsonword = input(&#x27;请输入想翻译的单词或句子：&#x27;)url = &quot;http://fanyi.youdao.com/translate?smartresult=dict&amp;&quot;header = &#123;&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36 Edg/87.0.664.41&quot;&#125;data = &#123; &#x27;i&#x27; : word, &#x27;from&#x27; : &#x27;AUTO&#x27;, &#x27;to&#x27; : &#x27;AUTO&#x27;, &#x27;smartresult&#x27; : &#x27;dict&#x27;, &#x27;client&#x27; : &#x27;fanyideskweb&#x27;, &#x27;salt&#x27; : &#x27;16096771607986&#x27;, &#x27;sign&#x27; : &#x27;e72a9ef79c90a05a621157815772b913&#x27;, &#x27;lts&#x27; : &#x27;1609677160798&#x27;, &#x27;bv&#x27; : &#x27;4f7ca50d9eda878f3f40fb696cce4d6d&#x27;, &#x27;doctype&#x27; : &#x27;json&#x27;, &#x27;version&#x27; : &#x27;2.1&#x27;, &#x27;keyfrom&#x27; : &#x27;fanyi.web&#x27;, &#x27;action&#x27; : &#x27;FY_BY_REALTlME&#x27;, &#125;response = requests.post(url=url,data=data,headers=header).content.decode()res = json.loads(response)print(res[&#x27;translateResult&#x27;][0][0][&#x27;tgt&#x27;]) 知己知彼，进行网页审查 打开网页，F12把network的这个勾选上，选上了以后可以保存请求记录 随便输入一个单词点击翻译，找到这个箭头指的东西 url记录下来待会配置要用，记得我刚刚说的要把里面的_o删掉喔，不然爬不到的 发现这个网页是用post的方式传参的 翻到下面，把数据信息全部扒下来， 可以发现i的值就是我们输入的单词 from和to就是转换的语言，其他的不知道是什么，全部扒下来就是了 在这里发现返回的值是json的格式，所以我们需要导入json库来对其解码 按老方法整就是了1234567891011121314151617181920import requestsimport jsonword = input(&#x27;请输入想翻译的单词或句子：&#x27;)url = &quot;http://fanyi.youdao.com/translate?smartresult=dict&amp;&quot;header = &#123;&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36 Edg/87.0.664.41&quot;&#125;data = &#123; &#x27;i&#x27; : word, &#x27;from&#x27; : &#x27;AUTO&#x27;, &#x27;to&#x27; : &#x27;AUTO&#x27;, &#x27;smartresult&#x27; : &#x27;dict&#x27;, &#x27;client&#x27; : &#x27;fanyideskweb&#x27;, &#x27;salt&#x27; : &#x27;16096771607986&#x27;, &#x27;sign&#x27; : &#x27;e72a9ef79c90a05a621157815772b913&#x27;, &#x27;lts&#x27; : &#x27;1609677160798&#x27;, &#x27;bv&#x27; : &#x27;4f7ca50d9eda878f3f40fb696cce4d6d&#x27;, &#x27;doctype&#x27; : &#x27;json&#x27;, &#x27;version&#x27; : &#x27;2.1&#x27;, &#x27;keyfrom&#x27; : &#x27;fanyi.web&#x27;, &#x27;action&#x27; : &#x27;FY_BY_REALTlME&#x27;, &#125; 接下来对翻译功能进行爬取 .content是转成二进制的意思 .decode()是指定编译格式，默认编码为字符串编码123response = requests.post(url=url,data=data,headers=header).content.decode()res = json.loads(response)print(res[&#x27;translateResult&#x27;][0][0][&#x27;tgt&#x27;]) 如果不进行json的解码，直接打印response的话 发现返回了一个字典，我们直接选中字典里的东西，会出现报错原因是这个其实是一串字符串，不是字典，只是长的和字典一样所以我们需要使用json.loads()函数来给他解个码，json库的详细解释这个博客说的很详细这个函数的具体作用就是：json.loads()函数可以将字符串转化为字典，但要保证,该字符串是以json格式组成的字符串，解完了码以后res是一个字典，我们就可以直接选中需要的东西了 那么什么是json勒JSON:一种与开发语言无关的、轻量级的数据存储格式格式：他有两种格式 Object{key:value,key:value…}key：string类型value：任何基本类型或数据结构 Array[value,value…]value：任何基本类型或数据结构。比如：{“name”:”李广”, “values”:[1,2,45,”你好”] } 总的来说就是类似于字典的格式，主要用来配置属性的（就像你玩一个游戏操控主角，主角的hp，mp是多少多少）更详细的解释可以看这篇博客","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"},{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"爬虫学习笔记1","slug":"爬虫入门学习笔记1","date":"2021-01-01T15:20:24.433Z","updated":"2021-01-03T14:49:32.513Z","comments":true,"path":"2021/01/01/爬虫入门学习笔记1/","link":"","permalink":"http://example.com/2021/01/01/%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/","excerpt":"","text":"爬虫入门学习笔记整了这么久，终于轮到爬虫了，之前一直对爬虫有所向往，现在学起来也是觉得很有意思，主要是通过一些大佬的博客来学习的，以下是我学习爬虫的学习笔记。 安装requests和BeautifulSoup4安装request：python本身提供的urllib没有python社区的requests库好用，现在主流都是用request来制作爬虫 打开cmd控制台 pip安装指令pip install requests 安装BeautifulSoup4：有了requests模块，可以使用他的get()方法来下载网页，但是下载的是网页的源代码，不利于信息的检索，所以有这个库来对其解析 打开cmd控制台 pip安装指令pip install bs4 开始写第一个爬虫，爬取百度网页爬取网页有几个步骤 指定你要爬取的url 使用requests的get方法来发起请求，返回响应对象 获取响应数据，转换成我们看得懂的形式 将爬取的内容储存 导入数据库1import requests 指定URL1u=&quot;https://www.baidu.com/&quot; 使用get方法爬取1response=requests.get(url=u) 设置编码为“utf-8”，不然网页打开是乱码1response.encoding = &quot;utf-8&quot; 获取响应数据，以text的形式给page1page=response.text 查看到response的形式是这个，所以要用.text来把他转化成文本格式 储存，把内容写进创建的baidu.html文件中12with open(&quot;baidu.html&quot;,&quot;w&quot;,encoding=&quot;utf-8&quot;) as f: f.write(page) 然后发现文件夹里就多了一个baidu的html文件 我的第二个爬虫，动态页面的爬取我们使用百度搜索一个东西，比如搜素爬虫，用上一个爬虫的方法不能爬取这个，要爬取动态页面，要给爬虫一个header找到这个user-agent，这个是给服务器说明访问的浏览器的信息（可以理解为一个身份证）在爬虫文件中创建一个字典 1idcard=&#123;&#x27;User-Agent&#x27;:&#x27;xxxxxxxxxxxxxxxxxxxxxxxxxx&#x27;&#125; 在调用get()方法的时候给他一个headers属性，内容是刚刚创建的字典然后剩下的操作还是看那四部 1234567import requestsurl=&quot;https://www.baidu.com/s?wd=爬虫&quot;idcard=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot;&#125;response=requests.get(url=url,headers=idcard) # 给他headers属性file=response.textwith open (&quot;wd.html&quot;,&quot;w&quot;,encoding=&#x27;utf-8&#x27;) as wd: wd.write(file) 发现文件中有wd.html文件了，打开就是搜索爬虫得到的网页了 爬虫etree配合xpath语句的学习并爬取b站分类表xpath是XML的路径语言，常与lxml库一起来解析网站完整详解这个博客中有比较详细介绍下面介绍我的学习思路 安装lxml控制台pip install lxml没啥好说的 导入库12import requestsfrom lxml import etree 通过etree.HTML()来解析网站,把网页数据解析 请求信息，处理信息 要爬取b站的信息，url设置到b站12url=&#x27;https://www.bilibili.com/&#x27;header=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot;&#125; 把爬取的信息文本化 1response=requests.get(url=url,headers=header).text 根据大佬的博客所说，把解析网站比喻成把网页数据变成一个大树，我们只取里面的几片叶子 1tree=etree.HTML(response) 接触到了xpath1leaf=tree.xpath(&#x27;//div[@id=&quot;primaryChannelMenu&quot;]/span/div[2]/a/span/text()&#x27;) 这时候print(leaf)就有结果了返回了一个列表，里面成功爬取了分类 xpath详解我自己的语法理解： 每递进一层就加一个/标签名 开头就是//两个斜杠就是直接跳转，不从开头开始一层一层的推 选择标签内的属性就用@属性名 选择有特殊标记的标签的语法//标签名[@属性名=&quot;xxx&quot;] 一层一层的推下去推到最后的时候选择要取得的信息：1，如果是标签里的文本信息就在最后加/text()如/a/span/text()2，如果是标签里面的属性就在最后加/@属性名如/a/@href 如果是很多兄弟元素可以使用标签名[排序数字]来选择例如div[1],这个排列数字是从1开始的，意思是第几个 例题 从根部开始，一级一级的找到了‘动画’xpath就可以写成：/html/body/div[2]/div/div[1]/div[3]/div/div[2]/span[1]/div/a/span/text()div[2]表示的是同级下第二个div，因为上面的svg标签里还有个div标签优化写法：因为我只要爬取这里的分类标签，所以：//div[@id=“primaryChannelMenu”]/span[1]/div/a/span/text() 这里只爬取了第一个“动画”，要爬取全部分类还得改一下这里有一排span标签，每一个都是一个分类，要把他里面的所以分类名爬取出来,我们就不要给span排列数字了，让他全选中leaf=tree.xpath(&#39;//div[@id=&quot;primaryChannelMenu&quot;]/span/div[2]/a/span/text()&#39;)成功！！！ 尝试图片的爬取这个网站很简单，结构都很简单，爬取里面的图片先附上完整的代码 123456789101112import requestsfrom lxml import etreeurl=&quot;https://www.qqtn.com/article/article_292075_1.html&quot;header=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot;&#125;response=requests.get(url=url,headers=header).texttree=etree.HTML(response)leaf=tree.xpath(&#x27;//div[@id=&quot;zoom&quot;]/p/img/@src&#x27;)for i in leaf: a=requests.get(url=i,headers=header).content name=i.split(&quot;/&quot;)[-1] with open(name,&quot;wb&quot;) as f: f.write(a) 详解如下 导入库12import requestsfrom lxml import etree 设置响应头，把爬取网页信息并处理1234url=&quot;https://www.qqtn.com/article/article_292075_1.html&quot;header=&#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36&quot;&#125;response=requests.get(url=url,headers=header).texttree=etree.HTML(response) 写xpath语句 1leaf=tree.xpath(&#x27;//div[@id=&quot;zoom&quot;]/p/img/@src&#x27;) 图片是id=&quot;zoom&quot;的div里面的，所以可以双斜杠直接跳到这，发现第一个p没有图片而是文字介绍，不过没关系，第二个开始的p开始才有img标签，所以直接这样写可以忽略掉第一个p，最后选择img标签里的src属性 图片的储存这个时候直打印leaf出来的是图片的地址的列表我们要提取里面的图片并保存，就遍历这个列表，每次循环将图片保存下来 12345for i in leaf: a=requests.get(url=i,headers=header).content name=i.split(&quot;/&quot;)[-1] with open(name,&quot;wb&quot;) as f: f.write(a) 因为每次循环的i都是地址，所以我们继续用requests.get()方法来爬取图片网站，爬取下来要用二进制的形式来保存，就是加上.content（图片，视频，音频都是要用二进制来爬取的，要爬取文字就用.text） 命名图片，看他的地址https://pic.qqtn.com/up/2020-3/15847100617620054.jpg最后是xxxx.jpg，所以我们用字符串的切片split()以”/“来对地址切片，选择倒数第一片就是xxxx.jpg了 储存图片，命名是完整的，有jpg的后缀，所以我们直接open就行，注意打开方式是”wb”，因为我们前面是用二进制的形式爬取的内容，所以”b”不能忘记了 运行成功！！！","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"},{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"}]},{"title":"Hexo博客的双线部署（github+coding）绑定自定义域名，以及遇到问题","slug":"Hexo博客的双线部署（github+coding）绑定自定义域名，以及遇到问题","date":"2020-12-27T09:45:33.626Z","updated":"2020-12-27T11:24:11.269Z","comments":true,"path":"2020/12/27/Hexo博客的双线部署（github+coding）绑定自定义域名，以及遇到问题/","link":"","permalink":"http://example.com/2020/12/27/Hexo%E5%8D%9A%E5%AE%A2%E7%9A%84%E5%8F%8C%E7%BA%BF%E9%83%A8%E7%BD%B2%EF%BC%88github+coding%EF%BC%89%E7%BB%91%E5%AE%9A%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9F%9F%E5%90%8D%EF%BC%8C%E4%BB%A5%E5%8F%8A%E9%81%87%E5%88%B0%E9%97%AE%E9%A2%98/","excerpt":"","text":"Hexo博客的双线部署（github+coding）绑定自定义域名，以及遇到问题前段时间装修了一下我的博客,发现好看是好看了，但是访问速度慢下来了，安装了图片懒加载还是太慢，杯水车薪。后来看到双线部署的概念 把博客部署到github给境外使用，部署到coding给境内使用，这样访问速度会快很多。 本博客是基于已在github搭建了博客的基础上写的，如果github还没部署不推荐直接就双线部署 coding改版了，静态页面也改版了，分配到域名不像以前一样和github差不多，现在提供的域名是一个很大一串不美观的域名，不知道是我操作的问题还是改变了就是这样，希望大佬指正绑定ssh密钥这个步骤和绑定在github如出一辙，我就不多说了，coding界面也是中文的。与之前不一样的是注册的是团队，不能直接以个人注册了，并不妨碍 创建项目coding官方推荐的是这个，那就选这个吧 按提示创建好项目就行和库就行 修改config配置文件照着这个格式来，我推荐的是绑定ssh的地址，不用输入密码比较方便哈哈哈然后hexo cl &amp;&amp; hexo g &amp;&amp; hexo d 三件套推上去就行了发现coding也有了 绑定自定义域名我是在腾讯云买的域名，这个见仁见智，喜欢到哪就到哪买呗DNS域名解析我也是在腾讯的DNSPod解析的照这样解析设置好coding有一个很坑的，现在静态页面跑到了下面，要自己打开持续部署打开静态页面创建一个网站节点就选香港吧，不用备案我这里出现了一个问题，自己搭建好的hexo不能选择网站类型中的hexo，会部署失败，但是代码来源选示例仓库就可以部署 下一步点自定义域名，把你买的域名输入进去，按照他说的在DNSPod解析域名处添加顺便把github的一起设置好 这里coding改版了，他给的地址是一大串东西而他给的CNAME 指向却不是这个地址设置好之后点一下部署，等个几分钟就可以访问了 讲一下github这边，github这边特别简单，打开你博客的仓库，打开设置往下翻，找到github pages，如图填写好就可以了可以发现我们的境内和境外已经分开了 我遇到的问题问题就出来了，我发现部署到coding后访问速度还是特别慢，他的ip根本就不是之前创建静态页面时选的香港，而还是国外的ip，访问速度和github一样慢甚至还更慢这不行，这还更慢我为什么还要双线部署，我就强行把CNAME指向改到了coding给的那个一大串的地址，访问速度一下就起来了但是这样做不行，证书不是你的，访问都有危险提示 所以我现在很迷惑，为什么给我的ip是国外的不能是那个香港的，coding为什么把这两个地址分开来，这样失去了双线部署的意义想求助一下大佬我哪个地方做错了？","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"博客搭建","slug":"博客搭建","permalink":"http://example.com/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"域名部署","slug":"域名部署","permalink":"http://example.com/tags/%E5%9F%9F%E5%90%8D%E9%83%A8%E7%BD%B2/"}]},{"title":"butterfly主题配置记录","slug":"butterfly配置记录","date":"2020-12-26T12:33:59.091Z","updated":"2020-12-26T12:36:57.323Z","comments":true,"path":"2020/12/26/butterfly配置记录/","link":"","permalink":"http://example.com/2020/12/26/butterfly%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/","excerpt":"","text":"安装依赖一开始要输入这个代码，不然打不开 1npm install hexo-renderer-pug hexo-renderer-stylus --save 添加关于和标签这两个不能直接去掉标注就生效，要生成一个page还要在md文件里加上 1234---title: tagsdate: 2020年12月24日15:14:16type: &quot;tags&quot; 1234---title: aboutdate: 2020年12月24日15:14:16type: &quot;about&quot; 添加鼠标和文字样式参考小康大佬参考木槿大佬把代码添加到：\\Butterfly\\source\\css\\_third-partynormalize.min.css末尾 背景的自定义参考大佬的博客：小康大佬自建一个css文件，在主题配置文件inject处引入 图片懒加载详情请看作者github：https://github.com/Troy-Yang/hexo-lazyload-image大佬的插件推荐：justlovesmile大佬 添加Valine大佬的博客X北辰北大佬博客讲的很详细了，主要提示一下butterfly主题有个小坑这里要把注释去掉，不是在冒号后面加Valine","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"Python学习笔记","slug":"Python学习笔记","date":"2020-12-23T16:37:55.295Z","updated":"2020-12-30T15:49:21.507Z","comments":true,"path":"2020/12/24/Python学习笔记/","link":"","permalink":"http://example.com/2020/12/24/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Python中__new__函数的理解在小甲鱼的课程里，学到了__new__函数的时候，我刚看完他的例子，我是一脸懵逼啊，一点都没有头绪，为啥这样做？在看了几篇博客以后我稍有理解，在这里记录一下 new 是在一个对象实例化的时候所调用的第一个方法。它跟其他魔法方法不同，它的第一个参数不是 self 而是这个类（cls），而其他的参数会直接传递给 init 方法的。 个人理解：new方法是会在init方法前调用的，除了第一个参数，其他参数会返回给init 123456class Do (str): #继承str的方法 def __new__(cls,itstr): #调用__new__函数，传入字符串itstr itstr = itstr.upper() # 把每个字母大写 return str.__new__(cls,itstr) #返回实例对象给__init__函数d = Do(&#x27;AbcDeFg&#x27;) #创建实例对象print(d) 创建实例对象d的时候，本来是调用init函数的但是由于我们重写了new函数，所以在调用init函数之前会先调用new函数我们重写的new函数第二个参数是itstr，但是我们还要加工后再返回给init所以在加工完后return里写str.__new__(cls,itstr)重新调用new函数后把加工后的itstr返回给init函数所以在调用完了new后开始调用init时，init收到的参数是加工后的itstr，所以d的值就是“ABCDEFG”了 利用这个特点，我们可以在实例化初始化之前对传入的参数进行修改计算，修改以后再传给init，通熟的说就是“掉包”，例如 1234class Do(float): # 继承浮点数的方法 def __new__(cls, num): # 传入参数num return float.__new__(cls, num*1.5) # 对num加工后返回给initprint(Do(12)) 对类和对象，self，__init__的理解类和对象首先要拿class创建一个类，这个类就相当于一个图纸，创建对象就是类的实例化，就相当于那图纸造屋子，对象名=类名()就算是给这个类创建了一个对象，这个对象就是在这个类里面了 self一个类可以生成无数个对象，当对象的方法被调用时，对象会将自身作为第一个参数传给这个方法，这个时候python才知道到底这个方法是给哪个对象用的，所以这个self就像是一把钥匙，对应着这个对象对应的门。比如下面的代码 12345678class Person: # 创建了一个名为Person的类 def setname (self,itname): # 创建一个名为setname的方法，第一个参数为self self.itname = itname # 因为itname是外部变量，要在类中使用要加工 def printname (self): print(&quot;我是%s&quot; % self.itname)a = Person() # 实例化aa.setname(&quot;小明&quot;) # a作为self参数传入，&quot;小明&quot;作为itname参数传入a.printname() 对于self.itname的理解：itname是全局变量，要在类中使用还得加工一下，使用self.变量名将外部的变量引入类中使用，不加self.会被当做普通变量。 其实self的意义是绑定 12345678910class D: def setxy (self,x,y): self.x = x self.y = y def printxy(self): print(self.x,self.y)dd = D()dd.setxy(1,2) # 这一步实际上是这样调用的dd.setxy(dd,1,2)# 这个时候x=1,y=2是dd实例的私有的绑定在dd上的属性# 连类对象D都没有这个属性，del D删除了类对象dd.printxy()一样能打印出来 提示：可以使用__dict__方法查看对象的属性如dd.__dict__ init这是一个构造函数（构造方法），实例化对象时，该方法会在对象被创建的时候自动调用，实例化对象的时候是可以传入参数的，这些参数会自动传入该方法中，通过重写该方法可以自定义对象的初始化操作，不重写就默认调用init(self)。，类名就作为self，看如下代码。 1234567class Person: def __init__ (self,itname): # 额外添加一个参数，实例化对象时输入的内容就作为itname的参数 self.itname = itname def printname (self): print(&quot;我是%s&quot; % self.itname)a = Person(&quot;小明&quot;) # 创建类的时候就可以直接传入参数，类名作为self，&quot;小明&quot;作为itnamea.printname() 用类和对象写一个计时器在学了一些类和对象之后，在书上看到一个例子，用类和对象打造一个计时器，我一开始没有思路，大概看了一下书上的例题后有了思路，下面是我自己写的代码（借鉴例子） 1234567891011121314151617import timeimport mathclass Count: def start(self): self.start=time.localtime() print(&quot;开始计时&quot;) def stop(self): self.stop=time.localtime() self.do() print(&quot;计时结束&quot;) def do(self): self.sec=math.fabs(self.stop[5]-self.start[5]) self.min=self.stop[4]-self.start[4] print(&quot;运行了%d秒&quot; % (self.sec+self.min*60))t=Count()t.start()t.stop() 首先我去查了一下time模块的内容，找到了这个用法说明 12345#作用：用于单独获取时间的某一部分t = time.localtime()print(t)#输出结果time.struct_time(tm_year=2020, tm_mon=12, tm_mday=18, tm_hour=20, tm_min=57, tm_sec=2, tm_wday=4, tm_yday=353, tm_isdst=0) 他会返回一个元组，下标是4，5对应分钟和秒钟，只需要让他们相减就可以 看了书上的写法，比我的高明很多，先留坑，以后把改善后的代码补回来","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}]},{"title":"vscode使用笔记","slug":"vscode使用笔记","date":"2020-12-12T16:00:00.000Z","updated":"2020-12-16T15:17:37.889Z","comments":true,"path":"2020/12/13/vscode使用笔记/","link":"","permalink":"http://example.com/2020/12/13/vscode%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","excerpt":"vscode使用笔记","text":"vscode使用笔记 推荐安装的插件这里主要推荐三款核心插件，其余的可以按需选择。 1.Markdown All in One：目前 Vscode 最流行的 Markdown 语法解析器。 2.Markdown PDF：使用的 Markdown 文件渲染导出插件。 3.Markdown TOC：一款针对 Github 等平台自动生成文章目录的插件（目前主流的博客平台如 CSDN 已经不需要自己在文中生成目录了）。 使用vscode预览Markdown文件 VScode已经默认集成markdown文档编辑插件,所以编辑md文件时已经有代码高亮。要实时预览的话按Ctrl+shift+p 后搜索Markdown找到这个 或使用快捷键Ctrl+k 放掉以后再按v 导入图片导入图片语法： 只记录一种图片插入方式 1![](xxx.png) 可以是本地的路径也可以是网络上的图片地址 导入代码块1使用&#96;&#96;&#96;代码内容&#96;&#96;&#96; 大佬的博客有更全面的介绍https://www.cnblogs.com/jpfss/p/10941921.html vscode配置c/c++编译调试环境下载好MinGW，配置系统环境 安装插件打开vscode把这两个插件安装好，按这个小三角就可以直接运行了 配置调试环境但是代码出现了问题不能调试，所以我们还得配置一下调试环境都选第一个会发现弹出一个文件，别管他直接关掉就好，现在的vscode会直接帮你配置好，不需要像其他博主那样自己创建自己输入现在就可以调试了，大功告成","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"},{"name":"vscode","slug":"vscode","permalink":"http://example.com/tags/vscode/"}]},{"title":"前端学习笔记","slug":"前端学习笔记HTML5，CSS3（更新中）","date":"2020-12-12T16:00:00.000Z","updated":"2020-12-26T08:52:46.667Z","comments":true,"path":"2020/12/13/前端学习笔记HTML5，CSS3（更新中）/","link":"","permalink":"http://example.com/2020/12/13/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0HTML5%EF%BC%8CCSS3%EF%BC%88%E6%9B%B4%E6%96%B0%E4%B8%AD%EF%BC%89/","excerpt":"前端学习笔记","text":"前端学习笔记 网页分成三个部分： 结构(HTML) 表现(CSS) 行为(JavaScript)css简介与使用1.内部样式 将样式编写到head中的style标签里然后通过CSS的选择器来选中元素并为其设置各种样式可以同时为多个标签设置样式，并且修改时只需要修改一处即可全部应用 内部样式表更加方便对样式进行复用 缺点：我们的内部样式表只能对一个网页起作用，它里边的样式不能跨页面进行复用 2.外部样式表以将CSS样式编写到一个外部的CSS文件中,然后通过link标签来引入外部的CSS文件 外部样式表需要通过link标签进行引入，意味着只要想使用这些样式的网页都可以对其进行引用使样式可以在不同页面之间进行复用 将样式编写到外部的CSS文件中，可以使用到浏览器的缓存机制，从而加快网页的加载速度，提高用户的体验。css的语法1.注释：/**/ 2.基本语法：选择器 声明块 选择器，通过选择器可以选中页面中的指定元素比如 p 的作用就是选中页面中所有的p元素 声明块，通过声明块来指定要为元素设置的样式声明块由一个一个的声明组成 声明是一个名值对结构一个样式名对应一个样式值，名和值之间：以:连接 ，以;结尾 选择器1.常用选择器 元素选择器作用：根据标签名来选中指定的元素语法：标签名{}例子：p{} h1{} div{} id选择器作用：给元素设定id属性，根据元素的id属性值选中一个元素 语法：#id属性值{} 例子：#box{} #red{} 类选择器作用：给元素设定，根据元素的class属性值选中一组元素 语法：.class属性值 好处：既可以给单一标签设定样式，也可以给一组标签设定样式 通配选择器 作用：选中页面中的所有元素 语法: * 2.复合选择器 交集选择器作用：选中同时复合多个条件的元素 语法：选择器1选择器2选择器3选择器n{} 注意点：交集选择器中如果有元素选择器，必须使用元素选择器开头 并集选择器作用：同时选择多个选择器对应的元素，其中可以是交集选择器语法：选择器1,选择器2,选择器3,选择器n{}例子： #b1,.p1,h1,span,div.red{} 关系选择器介绍标签关系： 123456789父元素：直接包含子元素的元素叫做父元素子元素：直接被父元素包含的元素是子元素祖先元素：1.直接或间接包含后代元素的元素叫做祖先元素2.一个元素的父元素也是它的祖先元素后代元素：1.直接或间接被祖先元素包含的元素叫做后代元素2.子元素也是后代元素兄弟元素：拥有相同父元素的元素是兄弟元素 子元素选择器作用：选中指定父元素的指定子元素 语法：父元素 &gt; 子元素 后代元素选择器作用：选中指定元素内的指定后代元素 语法：祖先 后代 兄弟选择器1.选择下一个兄弟 语法：前一个 + 下一个 选择紧贴着p的span的兄弟元素 2.选择下边所有的~符号后面标签名的兄弟 语法：兄 ~ 弟选择p后面的所有的span兄弟元素 属性选择器语法：[属性名] 选择含有指定属性的元素[属性名=属性值] 选择含有指定属性和属性值的元素[属性名^=属性值] 选择属性值以指定值开头的元素[属性名$=属性值] 选择属性值以指定值结尾的元素[属性名*=属性值] 选择属性值中含有某值的元素的元素 伪类选择器伪类（不存在的类，特殊的类）伪类用来描述一个元素的特殊状态比如：第一个子元素、被点击的元素、鼠标移入的元素…伪类一般情况下都是使用:开头 :empty 匹配冒号前面元素的类型中没有子元素的元素 :only-child 匹配他的父元素中只有唯一子元素的子元素(匹配的是冒号前的元素，也就是那个子元素) :first-child 第一个子元素:last-child 最后一个子元素:nth-child() 选中第n个子元素 :nth-last-child(n) 指定每个冒号前元素，匹配该元素的同级兄弟元素里倒数第n个元素 特殊值：n 第n个 n的范围0到正无穷2n 或 even 表示选中偶数位的元素2n+1 或 odd 表示选中奇数位的元素以上这些伪类都是根据所有的子元素进行排序 :first-of-type:last-of-type:nth-of-type():nth-last-of-child(n)这几个伪类的功能和上述的类似，不同点是他们是在冒号前元素的父元素里面的同类型元素中进行排序:not() 否定伪类将符合条件的元素从选择器中去除 a元素的伪类语法：:link 用来表示没访问过的链接（正常的链接）:visited 用来表示访问过的链接，由于隐私的原因，所以visited这个伪类只能修改链接的颜色。:hover 用来表示鼠标移入的状态:active 用来表示鼠标点击下去的瞬间（如果鼠标一直按住不放就不是瞬间哈哈哈） 直接在a元素里设置color属性，不管上面的点没点过，hover不hover都是那个颜色要想设置这些属性就再a:hover{colorxxx}就可以 伪元素选择器伪元素，表示页面中一些特殊的并不真实的存在的元素（特殊的位置）伪元素使用 :: 开头语法：::first-letter 表示第一个字母::first-line 表示第一行::selection 表示鼠标拖动选中的内容::before 元素的开始::after 元素的最后before 和 after 必须结合content属性来使用 选择器权重 样式 权重 内联样式 1000 id选择器 0100 类和伪类选择器 0010 元素选择器 0001 通配选择器 0000 继承 没有优先级 1.比较优先级时，需要将所有的选择器的优先级进行相加计算，最后优先级越高，则越优先显示（分组选择器是单独计算的）, 一般来说选择器越详细优先级越高。 2.选择器的累加不会超过其最大的数量级，类选择器在高也不会超过id选择器如果优先级计算后相同，此时则优先使用靠下的样式 3.可以在某一个样式的后边添加 !important ，则此时该样式会获取到最高的优先级，甚至超过内联样式。注意：在开发中这个玩意一定要慎用！ 单位长度单位 像素屏幕（显示器）实际上是由一个一个的小点点构成的不同屏幕的像素大小是不同的，像素越小的屏幕显示的效果越清晰所以同样的200px在不同的设备下显示效果不一样 百分比也可以将属性值设置为相对于其父元素属性的百分比设置百分比可以使子元素跟随父元素的改变而改变 emem是相对于元素的字体大小来计算的1em = 1font-size系统默认的font-size是16pxem会根据字体大小的改变而改变当加上font-size时会根据font-size来布置 remrem是相对于根元素的字体大小来计算与em同理，只不过他认定的font-size是根元素html里的font-size 123html&#123; font-size=10px&#125; 颜色颜色单位 颜色名在CSS中可以直接使用颜色名来设置各种颜色比如：red、orange、yellow、blue、green … …但是在css中直接使用颜色名是非常的不方便 RGB值：RGB通过三种颜色的不同浓度来调配出不同的颜色R：red，G：green ，B：blue每一种颜色的范围在 0 - 255 (0% - 100%) 之间语法：RGB(红色,绿色,蓝色) RGBA:就是在rgb的基础上增加了一个a表示不透明度需要四个值，前三个和rgb一样，第四个表示不透明度1表示完全不透明 0表示完全透明 .5半透明 十六进制的RGB值：语法：#红色绿色蓝色颜色浓度通过 00-ff如果颜色两位两位重复可以进行简写#aabbcc –&gt; #abc，而#aabbcd就不能简写一定要RGB每一项都两两重复 HSL值 HSLA值H 色相(0 - 360)S 饱和度，颜色的浓度 0% - 100%（100%最正）L 亮度，颜色的亮度 0% - 100%（50%最正）A 不透明度，和之前的一样 layout关系着整个网页的布局 文档流文档流（normal flow） 网页是一个多层的结构，一层摞着一层 通过CSS可以分别为每一层来设置样式 作为用户来讲只能看到最顶上一层 这些层中，最底下的一层称为文档流，文档流是网页的基础 我们所创建的元素默认都是在文档流中进行排列 对于我们来元素主要有两个状态 在文档流中 不在文档流中（脱离文档流） 元素在文档流中有什么特点：块元素： 块元素会在页面中独占一行(自上向下垂直排列) 默认宽度是父元素的全部（会把父元素撑满） 默认高度是被内容撑开（子元素） 行内元素： 行内元素不会独占页面的一行，只占自身的大小 行内元素在页面中左向右水平排列，如果一行之中不能容纳下所有的行内元素则元素会换到第二行继续自左向右排列（书写习惯一致） 行内元素的默认宽度和高度都是被内容撑开 盒子模型盒模型、盒子模型、框模型（box model） CSS将页面中的所有元素都设置为了一个矩形的盒子 将元素设置为矩形的盒子后，对页面的布局就变成将不同的盒子摆放到不同的位置 每一个盒子都由一下几个部分组成：内容区（content）内边距（padding）边框（border）外边距（margin） 内容区（content），元素中的所有的子元素和文本内容都在内容区中排列内容区的大小由width 和 height两个属性来设置 width 设置内容区的宽度 height 设置内容区的高度 123width: 200px;height: 200px;background-color: #bfa; 边框（border），边框属于盒子边缘，边框里边属于盒子内部，出了边框都是盒子的外部边框的大小会影响到整个盒子的大小要设置边框，需要至少设置三个样式： 边框的宽度 border-width 边框的颜色 border-color 边框的样式 border-style 123border-width: 10px;border-color: red;border-style: solid 边框不会影响内容区的大小，但会影响整个盒子模型的大小 边框边框 (border) 边框的宽度 border-width 边框的颜色 border-color 边框的样式 border-style 宽度border-width: 10px; 默认值，一般都是 3个像素border-width可以用来指定四个方向的边框的宽度值的情况 四个值：上 右 下 左 三个值：上 左右 下 两个值：上下 左右 一个值：上下左右 除了border-width还有一组 border-xxx-widthxxx可以是 top right bottom left用来单独指定某一个边的宽度 颜色border-color用来指定边框的颜色，同样可以分别指定四个边的边框规则和border-width一样border-color也可以省略不写，如果省略了则自动使用color的颜色值 1color: red; 样式border-style 指定边框的样式，默认值是none 表示没有边框 solid 表示实线 dotted 点状虚线 dashed 虚线 double 双线 简写属性 border简写属性，通过该属性可以同时设置边框所有的相关样式，并且没有顺序要求 除了border以外还有四个 border-xxx border-top border-right border-bottom border-left 这个方式比较方便所以用的比较多 1border: 10px red solid; 内边距（padding） 内容区和边框之间的距离是内边距 一共有四个方向的内边距： padding-top padding-right padding-bottom padding-left 简写属性和border一样遵循上左下右规则padding: 10px 20px 30px 40px; 内边距的设置会影响到盒子的大小，背景颜色会延伸到内边距上 一共盒子的可见框的大小，由内容区 内边距 和 边框共同决定， 所以在计算盒子大小时，需要将这三个区域加到一起计算 外边距（margin）外边距不会影响盒子可见框的大小但是外边距会影响盒子的位置 一共有四个方向的外边距：margin-top：上外边距，设置一个正值，元素会向下移动margin-right：默认情况下设置margin-right不会产生任何效果margin-bottom：下外边距，设置一个正值，其下边的元素会向下移动margin-left：左外边距，设置一个正值，元素会向右移动 margin也可以设置负值，如果是负值则元素会向相反的方向移动 元素在页面中是按照自左向右的顺序排列的，都往左上角挤，所以默认情况下如果我们设置的左和上外边距则会移动元素自身，而设置下和右外边距会挤开其他元素 margin的简写属性：margin 可以同时设置四个方向的外边距 ，用法和padding一样 margin会影响到盒子的实际占用空间 盒子的水平布局元素的水平方向的布局：元素在其父元素中水平方向的位置由以下几个属性共同决定 margin-left border-left padding-left width padding-right border-right margin-right 一个元素在其父元素中，水平布局必须要满足以下的等式margin-left+border-left+padding-left+width+padding-right+border-right+margin-right = 其父元素内容区的宽度 （必须满足）以上等式必须满足，如果相加结果使等式不成立，则称为过度约束，则等式会自动调整调整的情况：1，如果这七个值中没有为 auto 的情况，则浏览器会自动调整margin-right值以使等式满足，所以之前说调margin-right不会有任何效果，一般来说margin-right是由浏览器自己来调节的。2，如果要设置auto，七个值有三个可以设置auto： width margin-left maring-right 1，如果将一个宽度和一个外边距设置为auto，则宽度会调整到最大，设置为auto的外边距会自动为0 2，如果将三个值都设置为auto，则外边距都是0，宽度最大 3，如果将两个外边距设置为auto，宽度固定值，则会将外边距设置为相同的值可以利用这个原理让元素在父元素中居中 12width:200px;margin:0 auto; 这个0是上下外边距，auto是左右外边距 总的来说1，七个属性要满足等式。2，如果不满足就会自动调整： 如果没设置auto则自动调整margin-right填满父元素 如果设置了auto分情况 垂直方向的布局默认情况下父元素的高度被内容撑开垂直方向上内容（包括子元素的边框边距等等）多高父元素就被撑的多高 如果父元素高度被设定，那该是多少就是多少。 子元素是在父元素的内容区中排列的，如果子元素的大小超过了父元素，则子元素会从父元素中溢出，使用 overflow 属性来设置父元素如何处理溢出的子元素可选值： visible，默认值 子元素会从父元素中溢出，在父元素外部的位置显示 hidden 溢出内容将会被裁剪不会显示 scroll 生成两个滚动条，通过滚动条来查看完整的内容 auto 根据需要生成滚动条（有的时候不需要两个滚动条，就用auto就好） 垂直外边距的折叠我们给这两个元素分别设置上下外边距的时候，有一个不生效 相邻的垂直方向外边距会发生重叠现象兄弟元素： 兄弟元素间的相邻垂直外边距会取两者之间的较大值（两者都是正值） 特殊情况：如果相邻的外边距一正一负，则取两者的和如果相邻的外边距都是负值，则取两者中绝对值较大的 兄弟元素之间的外边距的重叠，对于开发是有利的，所以我们不需要进行处理 父子元素： 父子元素间相邻外边距，子元素的会传递给父元素（上外边距） 父子外边距的折叠会影响到页面的布局，必须要进行处理方法1：设置父元素的padding再改height方法2：以后再说更好的 行内元素的盒模型行内元素的盒模型 行内元素不支持设置宽度和高度 行内元素可以设置padding，但是垂直方向padding不会影响页面的布局 行内元素可以设置border，垂直方向的border不会影响页面的布局 行内元素可以设置margin，垂直方向的margin不会影响布局display 用来设置元素显示的类型可选值： inline 将元素设置为行内元素 block 将元素设置为块元素 inline-block 将元素设置为行内块元素行内块，既可以设置宽度和高度又不会独占一行 table 将元素设置为一个表格 none 元素不在页面中显示a是行内元素，通过display把他设置成块元素，宽高就能实现了 visibility 用来设置元素的显示状态可选值： visible 默认值，元素在页面中正常显示 hidden 元素在页面中隐藏 不显示，但是依然占据页面的位置与none的区别，none直接是消失，不会给他留位置","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"},{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"hexo主题yilia个性化","slug":"hexo主题yilia个性化","date":"2020-12-11T16:00:00.000Z","updated":"2020-12-12T03:58:03.494Z","comments":true,"path":"2020/12/12/hexo主题yilia个性化/","link":"","permalink":"http://example.com/2020/12/12/hexo%E4%B8%BB%E9%A2%98yilia%E4%B8%AA%E6%80%A7%E5%8C%96/","excerpt":"展开全文的美化","text":"展开全文的美化 在md文件中加这个标签会有两个跑出来，我觉得很不美观所以找了另一个办法在yilia的_config.yml中把这个more改成空格就行了 为博客网站更换logo1.将图片放在yilia的img文件夹里 2.在yilia的config文件里把路径加上 展开全文的使用1、node.js版本必须6.2以上2、在hexo根目录下执行命令：npm i hexo-generator-json-content --save3.在根目录下的config里加入 123456789101112131415161718jsonContent: meta: false pages: false posts: title: true date: true path: true text: false raw: false content: false slug: false updated: false comments: false link: false permalink: false excerpt: false categories: false tags: true 但是我的出现了问题没有标题在上面，那就没什么用了后来查资料我发现要在md文件头部加上这个东西title是标题，所有文章的索引就是依靠这个东西来标注的，tags是标签，要注意tags的格式不要搞错了。 左侧栏的美化不知道是不是我自己的原因，在根目录改的作者名和个性签名不能显示出来，所以一言也无法使用，后来百度了一下，说是现在的yilia会优先选择主题的author和subtitle，所以要在yilia的config文件里加上author和subtitle。 添加一言后来检查了一些别的大佬的主题设置，发现这样写是可以加上一言的在layout\\partial\\left-col文件里找到&lt;p class=&quot;header-subtitle&quot;&gt;&lt;%=theme.subtitle%&gt;&lt;/p&gt;，把他换成下面这几段 1234&lt;a id=&quot;hitokoto&quot; href=&quot;#&quot; onmouseover=&quot;this.style.color=&#x27;#7fffd4&#x27;;&quot; onmouseout=&quot;this.style.color=&#x27;aliceblue&#x27;;&quot;&gt;_(:з」∠)_ 加载中...&lt;/a&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/bluebird@3/js/browser/bluebird.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/whatwg-fetch@2.0.3/fetch.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://v1.hitokoto.cn/?encode=js&amp;select=%23hitokoto&quot; defer&gt;&lt;/script&gt; 这样就可以了 为左边栏子自定义图片背景1.打开\\themes\\yilia\\source\\main.xxxx.css文件 2.用你的编辑器在里面找到.left-col{ 3.在这个标签里删除background属性并加上background-image:url(“”);属性","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"yilia","slug":"yilia","permalink":"http://example.com/tags/yilia/"}]},{"title":"github上搭建好个人博客上传文件没有小绿格记录","slug":"github上搭建好个人博客上传文件没有小绿格记录","date":"2020-12-08T16:00:00.000Z","updated":"2020-12-13T06:41:10.263Z","comments":true,"path":"2020/12/09/github上搭建好个人博客上传文件没有小绿格记录/","link":"","permalink":"http://example.com/2020/12/09/github%E4%B8%8A%E6%90%AD%E5%BB%BA%E5%A5%BD%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E6%B2%A1%E6%9C%89%E5%B0%8F%E7%BB%BF%E6%A0%BC%E8%AE%B0%E5%BD%95/","excerpt":"github上搭建好个人博客上传文件没有小绿格记录","text":"github上搭建好个人博客上传文件没有小绿格记录 本来想搭建博客后在上面更新博客在github上打卡小绿格记录但是发现小绿格没有出来我搭建完博客后上传到github的内容是这么些，但是我上传博客却不是在这里上传我是把md文件放到这个文件夹里使用下面三个命令来实现博客推送而不是git push的方式 123hexo cleanhexo ghexo d 但是我看到第一个文件夹里其实有更新的博客但是就是没有小绿格我看了一下我有两个branch，main和master，我的博客文件放在master里，而一个无关紧要的branch main被我创建库的时候设成了default,于是我就想改一下分支，但是没搞懂git的使用方法原理，把博客搞崩溃了。我干脆就删掉那个库重新搭建了一个博客，这次我就只设置了一个分支master搭够好了博客后我就发现使用hexo的三部上传博客也可以出现小绿格了。","categories":[],"tags":[{"name":"github","slug":"github","permalink":"http://example.com/tags/github/"}]},{"title":"在github创建库并向上上传文件","slug":"在github创建库并向上上传文件","date":"2020-12-07T16:00:00.000Z","updated":"2020-12-20T15:02:16.451Z","comments":true,"path":"2020/12/08/在github创建库并向上上传文件/","link":"","permalink":"http://example.com/2020/12/08/%E5%9C%A8github%E5%88%9B%E5%BB%BA%E5%BA%93%E5%B9%B6%E5%90%91%E4%B8%8A%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6/","excerpt":"在github创建库并向上上传文件","text":"在github创建库并向上上传文件 我之前已经创建过库，绑定了密钥，所以省了很多步骤我就记录了一下过程怕自己忘记 1，先在github创建一个库复制这个链接到时要用 2.在本地创建一个文件夹在文件夹中使用git clone http....(这个是刚刚复制的地址)出现了你在github中创建的库的文件 上传文件1.打开后git bash here，将你要上传的文件放到里面再使用git add . 这个git add .的意思是：将项目上所有的文件添加到仓库中的意思，如果想添加某个特定的文件，只需把.换成这个特定的文件名。 2.使用git commit -m “xxx” xxx是该文件的提交的注释说明 3.使用git push -u origin main这个’main’是分支名，每个人可能不一样这一步做完就算完成了详细教学可以参考其一其二这个我觉得是写的最好的 以后要更新你的库就输入这几个命令：123git add .git commit -m &quot;&quot;git push origin main（那个-u是第一次上传的时候要用的） 每次push要输入密码push了几天以后，我发现每次push都要密码，贼麻烦，所以我就找了一下原因，原来我们直接clone下来的库默认是https的形式，所以每次都要输入密码但是如果改成ssh的形式就不用输入密码了具体的操作就看这个大佬的博客吧","categories":[],"tags":[{"name":"github","slug":"github","permalink":"http://example.com/tags/github/"}]},{"title":"指针练习","slug":"指针练习题","date":"2020-11-18T16:00:00.000Z","updated":"2020-12-13T06:41:12.611Z","comments":true,"path":"2020/11/19/指针练习题/","link":"","permalink":"http://example.com/2020/11/19/%E6%8C%87%E9%92%88%E7%BB%83%E4%B9%A0%E9%A2%98/","excerpt":"使用指针方法实现字符串逆序存放后再输出","text":"使用指针方法实现字符串逆序存放后再输出 编写程序：从键盘任意输入一个字符串，输出该字符串。然后，将该字符串逆序存放后再输出，要求用字符指针完成。（提示：逆序存放的函数接口：void invstr(char *s)） 123456789101112131415161718192021#include&lt;stdio.h&gt;#include&lt;string.h&gt;void invstr(char *s)&#123; char b; int len; len=strlen(s); /*获取该字符串的长度*/ for(int i=0;i&lt;len/2;i++)&#123; /*该循环的目的是每次将字符串的头和尾换一下位置*/ b=*(s+i); /*字符串的第i个元素的地址暂时放到b里*/ *(s+i)=*(s+len-1-i); /*将字符串的倒数第i个元素换到第i个元素*/ *(s+len-1-i)=b; /*再将b存放的地址放回倒数第i个元素*/ &#125; &#125;int main()&#123; char a[1000]; gets(a); /*输入字符串*/ printf(&quot;%s\\n&quot;,a); /*正序输出一次*/ invstr(a); /*运行函数*/ printf(&quot;%s&quot;,a); /*逆序输出*/ &#125; 利用指针编程，用指针方法编写一函数，实现两个字符串的比较。编程点拨：即自己编写一个strcmp函数：strcmp(s1,s2)，如果s1= s2，返回值为0，如果s1≠s2, 返回它们二者第一个不同字符的ASCII码差值(如”BOY”与”BAD”, 第二个字母不同，”O”与”A”之差为79-65=14)。如果要s1&gt;s2，则输出正值，如果s1&lt;s2，则输出负值。 123456789101112131415161718192021222324252627#include&lt;stdio.h&gt;#include&lt;string.h&gt;void strcmp(char *s1,char *s2)&#123; int len,i=0,sum=0,lenmax; lenmax = strlen(s1); len = strlen(s2); if(lenmax &lt; len)&#123; lenmax = len; &#125; for(i=0;i&lt;lenmax and sum==0;i++)&#123; if(*(s1+i) &gt; *(s1+i))&#123; sum = *(s1+i) - *(s2+i); &#125; if(*(s1+i) &lt; *(s2+i))&#123; sum = ( - (*(s1+i) - *(s2+i))); &#125; &#125; printf(&quot;%d&quot;,sum);&#125;int main()&#123; char s1[1000],s2[1000]; gets(s1); gets(s2); strcmp(s1,s2); &#125;","categories":[],"tags":[{"name":"c语言","slug":"c语言","permalink":"http://example.com/tags/c%E8%AF%AD%E8%A8%80/"},{"name":"指针","slug":"指针","permalink":"http://example.com/tags/%E6%8C%87%E9%92%88/"}]},{"title":"使用Hexo在Github上创建博客","slug":"使用Hexo在Github上创建博客","date":"2020-10-18T16:00:00.000Z","updated":"2021-01-02T17:54:43.766Z","comments":true,"path":"2020/10/19/使用Hexo在Github上创建博客/","link":"","permalink":"http://example.com/2020/10/19/%E4%BD%BF%E7%94%A8Hexo%E5%9C%A8Github%E4%B8%8A%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2/","excerpt":"使用Hexo在Github上创建博客","text":"使用Hexo在Github上创建博客 前言先说明一下，我在此时只是一位刚上大一的新生，还啥都不懂，文中如果有什么错误或不规范的地方请各位大佬斧正，我定会虚心接受。在10月18日晚上，学长给我布置了个作业，让我在github上构建属于自己的博客网站，我了解了一下，觉得有个属于自己的网站简直太帅了，于是就兴冲冲的开始了搭建，在10月19号下午，废物的我终于搭建好了。于是在此记录一下我搭建的过程。 一、安装必备插件Git，Node.js安装Git和Node.js我就不在此多加赘述，哪里都能找到，而且讲的也详细。 二、安装Hexo1、在电脑中创建文件夹比如我是这样创建的 2、进入这个文件夹按右键选择Git bash here打开小黑框 3、依次输入1npm install -g hexo 安装Hexo的基础框架。 1hexo init 初始化hexo。 1npm install 安装相关组件。 1hexo s 生成静态页面 这个时候你可以在本地访问自己的网站了。 但是也只仅限于你，接下来我们要把这玩意上传到Github里面，让所有人都能访问。 三、将本地内容上传到Github里1、注册一个Github账号2、创建一个仓库 3、配置Github的个人数据123git config --global user.name &quot;xxxname&quot; git config --global user.email &quot;xxxemail&quot; xxx是你自己的用户名，配置完成后可以输入下面的代码来验证 1git config --list 如果出现了问题，用下面两个代码重新设置 123$ git config --global --replace-all user.email &quot;输入你的邮箱&quot; $ git config --global --replace-all user.name &quot;输入你的名字&quot; 4、设置你的ssh密钥1ssh-keygen -t rsa -C &quot;xxxemail&quot; 注意上面代码的C要大写喔代码输入了以后一直按回车就好，直到出现这个页面就OK了然后我们可以直接在小黑框中调出密钥 1cat ~/.ssh/id_rsa.pub 从ssh-rsa开始一直到.com全部复制下来上传ssh就可以了像这样就成功了然后我们可以在小黑框上输入ssh -T git@github.com进行验证看到他和你打招呼了就意味着OK了 5、上传到Github用记事本打开这个文件，直接拉到最下面，按照这个格式打好，注意红点标注了的地方是有一个空格的 然后再到小黑框里输入npm install hexo-deployer-git --save 123hexo cleanhexo ghexo d 这个时候你的网站就算搭建完成了！可以让别人访问了http://你自己的用户名.github.io 上传博客将博客文件放到文件夹里后执行三个命令 123hexo cleanhexo ghexo d","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"github","slug":"github","permalink":"http://example.com/tags/github/"}]}],"categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/tags/%E7%AC%94%E8%AE%B0/"},{"name":"PHP","slug":"PHP","permalink":"http://example.com/tags/PHP/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"cookie","slug":"cookie","permalink":"http://example.com/tags/cookie/"},{"name":"协程","slug":"协程","permalink":"http://example.com/tags/%E5%8D%8F%E7%A8%8B/"},{"name":"事件循环","slug":"事件循环","permalink":"http://example.com/tags/%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF/"},{"name":"多线程","slug":"多线程","permalink":"http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"Python","slug":"Python","permalink":"http://example.com/tags/Python/"},{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"博客搭建","slug":"博客搭建","permalink":"http://example.com/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"域名部署","slug":"域名部署","permalink":"http://example.com/tags/%E5%9F%9F%E5%90%8D%E9%83%A8%E7%BD%B2/"},{"name":"vscode","slug":"vscode","permalink":"http://example.com/tags/vscode/"},{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"},{"name":"yilia","slug":"yilia","permalink":"http://example.com/tags/yilia/"},{"name":"github","slug":"github","permalink":"http://example.com/tags/github/"},{"name":"c语言","slug":"c语言","permalink":"http://example.com/tags/c%E8%AF%AD%E8%A8%80/"},{"name":"指针","slug":"指针","permalink":"http://example.com/tags/%E6%8C%87%E9%92%88/"}]}